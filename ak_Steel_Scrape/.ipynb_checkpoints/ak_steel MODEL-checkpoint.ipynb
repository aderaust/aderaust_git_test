{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python df_concat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ak_model_total = pd.read_csv('clean_ak_df', dtype = {'defect_code': 'object'}, float_precision='round_trip',\n",
    "                            index_col = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acer_vars = ['gauge', 'width', 'weight', 'carbon', 'manganese', 'sulfur', 'phosphorus', 'silicon', 'niobium',\n",
    "'vanadium', 'aluminium'] # all variables included in acermital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipeline for ak_steel webiste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating class to train a perceptron model based off th data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8272163201981928"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ak_steel_perceptron_model:\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, data = ak_model_total, variables = acer_vars):\n",
    "        \n",
    "        self.ak_clean_data = data.dropna()\n",
    "        \n",
    "        \n",
    "        self.train_data, self.test_data = train_test_split(self.ak_clean_data)\n",
    "        self.vars = variables # defining variables\n",
    "\n",
    "    def create_mlp(self):\n",
    "        # pulling values to be scaled \n",
    "       \n",
    "        X_train = self.train_data.loc[:, self.vars].values\n",
    "        \n",
    "        y_train = self.train_data.loc[:, \"price\"].values\n",
    "\n",
    "        X_test = self.test_data.loc[:, self.vars].values\n",
    "\n",
    "\n",
    "        y_test = self.test_data.loc[:, \"price\"].values\n",
    "\n",
    "    \n",
    "    \n",
    "        # standardizing input data for mlp regression \n",
    "    \n",
    "\n",
    "        x_scaler = StandardScaler() \n",
    "        \n",
    "        x_scaler.fit(X_train)  \n",
    "\n",
    "        X_train_scaled = x_scaler.transform(X_train)  \n",
    "        \n",
    "        X_test_scaled = x_scaler.transform(X_test)  \n",
    "        \n",
    "        \n",
    "        \n",
    "        # standardizing output data for mlp regression \n",
    "\n",
    "        y_train = y_train.reshape(-1,1)\n",
    "\n",
    "        y_scaler = StandardScaler()\n",
    "        \n",
    "\n",
    "        \n",
    "        y_scaler.fit(y_train)  \n",
    "\n",
    "        y_train_scaled = y_scaler.transform(y_train)  \n",
    "\n",
    "        # apply same transformation to test data\n",
    "\n",
    "        y_test = y_test.reshape(-1,1)\n",
    "\n",
    "\n",
    "        y_test_scaled = y_scaler.transform(y_test)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ak_regressor = MLPRegressor(max_iter=500)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "        self.y_scaler = y_scaler\n",
    "        \n",
    "        self.mlp_fitted = ak_regressor.fit(X_train_scaled, np.ravel(y_train_scaled))\n",
    "        \n",
    "        self.rscore = self.mlp_fitted.score(X_test_scaled, np.ravel(y_test_scaled))\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        return self\n",
    "\n",
    "        \n",
    "        \n",
    "#     def get_mlp_prediction(self, index): # return prediction based off of index_code/identifier\n",
    "        \n",
    "#         prediction = self.y_scaler.inverse_transform(self.mlp_fitted.predict(self.ak_clean_data.loc[index].reshape(1,-1)))\n",
    "\n",
    "        \n",
    "        \n",
    "#         return prediction\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "kk = ak_steel_perceptron_model()\n",
    "\n",
    "kk.create_mlp()\n",
    "\n",
    "\n",
    "kk.rscore\n",
    "\n",
    "# kk.get_mlp_prediction(40)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipline to download and open data from acermital targetsteel excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a function to download all 30 excel files, and concat them into a single excel file to be downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acermital_data_pretty = pd.read_excel('test_acermital_df.xlsx', skiprows=6, index_col='Piece ID / Ref#')\n",
    "\n",
    "\n",
    "\n",
    "acermital_data_model = acermital_data_pretty.drop(columns = ['Minor Product', 'Business Unit',\n",
    "       'Category', 'Location', 'Grade', 'Comment', 'Defect', 'Trans#'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing gauge issue\n",
    "\n",
    "def gauge_fix():\n",
    "    gauge_data = acermital_data_model['Gauge'].values\n",
    "    \n",
    "    pretty_gauges = []\n",
    "    for i in gauge_data:\n",
    "        pretty_gauges.append(float(i.split()[0]))\n",
    "    \n",
    "    return pretty_gauges\n",
    "\n",
    "\n",
    "acermital_data_model['Gauge'] = gauge_fix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fixing chem issue\n",
    "\n",
    "# def chem_fix():\n",
    "    \n",
    "#     chem_list = acermital_data_model['Chemistry'].values\n",
    "    \n",
    "#     chem_vars = acer_vars[3:]\n",
    "    \n",
    "#     chem_dict = {k:None for k in chem_vars }\n",
    "    \n",
    "#     for i in chem_list:\n",
    "#         intermed_chem = i.split()\n",
    "#         chem_dict.update('carbon' = intermed_chem[1])\n",
    "#         chem_dict.update('manganese' = intermed_chem[3])\n",
    "#         chem_dict.update('sulfur' = intermed_chem[5])\n",
    "#         chem_dict.update('silicon' = intermed_chem[7])\n",
    "#         chem_dict.update('niobium' = intermed_chem[9])\n",
    "#         chem_dict.update('vanadium' = intermed_chem[11])\n",
    "#         chem_dict.update('aluminium' = intermed_chem[13])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# #         for j, val in enumerate(acer_vars):\n",
    "# #             chem_order.append(chem_list[i].split()[j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:  .0883 MN: 1.0170 S:  .0039 P:  .0110 SI:  .3130 CB:  .0020 V:  .0020 AL:  .0480 TI:  .0030 B:  .00020 CR:  .0310 MO:  .0050 NI:  .0110'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_val[4].replace(\":\", \": \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_list = acermital_data_model['Chemistry'].values.tolist()\n",
    "\n",
    "\n",
    "chem_vars = acer_vars[3:]\n",
    "\n",
    "chem_dict = {k:None for k in chem_vars }\n",
    "\n",
    "chem_clean = []\n",
    "for i in chem_list:\n",
    "    chem_clean.append(i.replace(\":\",\": \").split())\n",
    "    \n",
    "chem_array = np.array(chem_clean)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carbon': None,\n",
       " 'manganese': None,\n",
       " 'sulfur': None,\n",
       " 'phosphorus': None,\n",
       " 'silicon': None,\n",
       " 'niobium': None,\n",
       " 'vanadium': None,\n",
       " 'aluminium': None}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['C:', '.0291', 'MN:', ..., '.0033', 'NI:', '.0106'],\n",
       "       ['C:', '.0290', 'MN:', ..., '.0033', 'NI:', '.0072'],\n",
       "       ['C:', '.0247', 'MN:', ..., '.0016', 'NI:', '.0041'],\n",
       "       ...,\n",
       "       ['C:', '.0437', 'MN:', ..., '.0050', 'NI:', '.0080'],\n",
       "       ['C:', '.0481', 'MN:', ..., '.0050', 'NI:', '.0120'],\n",
       "       ['C:', '.0442', 'MN:', ..., '.0040', 'NI:', '.0100']], dtype='<U6')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chem_dict['carbon'] = [float(i) for i in chem_array[:,1].tolist()]\n",
    "chem_dict['manganese'] = [float(i) for i in chem_array[:,3].tolist()]\n",
    "chem_dict['sulfur'] = [float(i) for i in chem_array[:,5].tolist()]\n",
    "chem_dict['phosphorus'] = [float(i) for i in chem_array[:,7].tolist()]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carbon': [0.0291,\n",
       "  0.029,\n",
       "  0.0247,\n",
       "  0.0247,\n",
       "  0.0883,\n",
       "  0.0904,\n",
       "  0.0865,\n",
       "  0.0842,\n",
       "  0.0854,\n",
       "  0.0865,\n",
       "  0.0842,\n",
       "  0.082,\n",
       "  0.0865,\n",
       "  0.0844,\n",
       "  0.0297,\n",
       "  0.0201,\n",
       "  0.0343,\n",
       "  0.0343,\n",
       "  0.0324,\n",
       "  0.0324,\n",
       "  0.0352,\n",
       "  0.0449,\n",
       "  0.0449,\n",
       "  0.0449,\n",
       "  0.0328,\n",
       "  0.0319,\n",
       "  0.0352,\n",
       "  0.0328,\n",
       "  0.0352,\n",
       "  0.0352,\n",
       "  0.0319,\n",
       "  0.0319,\n",
       "  0.0328,\n",
       "  0.0449,\n",
       "  0.0352,\n",
       "  0.0319,\n",
       "  0.0316,\n",
       "  0.0328,\n",
       "  0.0328,\n",
       "  0.0328,\n",
       "  0.0297,\n",
       "  0.0352,\n",
       "  0.0328,\n",
       "  0.0328,\n",
       "  0.0319,\n",
       "  0.0324,\n",
       "  0.0297,\n",
       "  0.0316,\n",
       "  0.0316,\n",
       "  0.0316,\n",
       "  0.0352,\n",
       "  0.032,\n",
       "  0.032,\n",
       "  0.0297,\n",
       "  0.0319,\n",
       "  0.0319,\n",
       "  0.0319,\n",
       "  0.0328,\n",
       "  0.0414,\n",
       "  0.0297,\n",
       "  0.0328,\n",
       "  0.0328,\n",
       "  0.0328,\n",
       "  0.0298,\n",
       "  0.0324,\n",
       "  0.0283,\n",
       "  0.0276,\n",
       "  0.029,\n",
       "  0.0305,\n",
       "  0.0262,\n",
       "  0.0369,\n",
       "  0.0186,\n",
       "  0.0328,\n",
       "  0.0014,\n",
       "  0.0357,\n",
       "  0.031,\n",
       "  0.0403,\n",
       "  0.0437,\n",
       "  0.0481,\n",
       "  0.0442],\n",
       " 'manganese': [0.2091,\n",
       "  0.1919,\n",
       "  0.2346,\n",
       "  0.2346,\n",
       "  1.017,\n",
       "  1.015,\n",
       "  1.02,\n",
       "  0.968,\n",
       "  1.026,\n",
       "  1.02,\n",
       "  0.968,\n",
       "  1.009,\n",
       "  1.02,\n",
       "  1.016,\n",
       "  0.187,\n",
       "  0.1952,\n",
       "  0.187,\n",
       "  0.187,\n",
       "  0.1979,\n",
       "  0.1979,\n",
       "  0.2325,\n",
       "  0.182,\n",
       "  0.182,\n",
       "  0.182,\n",
       "  0.1764,\n",
       "  0.1817,\n",
       "  0.2325,\n",
       "  0.1764,\n",
       "  0.2325,\n",
       "  0.2325,\n",
       "  0.1817,\n",
       "  0.1817,\n",
       "  0.1764,\n",
       "  0.182,\n",
       "  0.2325,\n",
       "  0.1817,\n",
       "  0.195,\n",
       "  0.1764,\n",
       "  0.1764,\n",
       "  0.1764,\n",
       "  0.2052,\n",
       "  0.2325,\n",
       "  0.1764,\n",
       "  0.1764,\n",
       "  0.1817,\n",
       "  0.1979,\n",
       "  0.2052,\n",
       "  0.195,\n",
       "  0.195,\n",
       "  0.195,\n",
       "  0.2325,\n",
       "  0.2063,\n",
       "  0.2063,\n",
       "  0.2052,\n",
       "  0.1817,\n",
       "  0.1817,\n",
       "  0.1817,\n",
       "  0.2123,\n",
       "  0.196,\n",
       "  0.2052,\n",
       "  0.2123,\n",
       "  0.2123,\n",
       "  0.2123,\n",
       "  0.1812,\n",
       "  0.1979,\n",
       "  0.1844,\n",
       "  0.205,\n",
       "  0.1953,\n",
       "  0.1869,\n",
       "  0.1869,\n",
       "  0.1848,\n",
       "  0.1923,\n",
       "  0.1952,\n",
       "  0.1044,\n",
       "  0.195,\n",
       "  0.1979,\n",
       "  0.215,\n",
       "  0.211,\n",
       "  0.205,\n",
       "  0.25],\n",
       " 'sulfur': None,\n",
       " 'phosphorus': None,\n",
       " 'silicon': None,\n",
       " 'niobium': None,\n",
       " 'vanadium': None,\n",
       " 'aluminium': None}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:',\n",
       "       'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:',\n",
       "       'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:',\n",
       "       'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:',\n",
       "       'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:',\n",
       "       'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:',\n",
       "       'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:', 'C:',\n",
       "       'C:', 'C:', 'C:'], dtype='<U6')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chem_array[np.where(chem_array == \"C:\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chem_fix():\n",
    "    chem_list = acermital_data_model['Chemistry'].values.tolist()\n",
    "    \n",
    "    chem_vars = acer_vars[3:]\n",
    "    \n",
    "    chem_dict = {k:None for k in chem_vars }\n",
    "    \n",
    "    chem_list = []\n",
    "    \n",
    "\n",
    "    for i in chem_val:\n",
    "        chem_list.append(i.split())\n",
    "        \n",
    "    return chem_list\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ak_regressor = MLPRegressor()\n",
    "\n",
    "# ak_regressor.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# ak_regressor.score(X_test, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaler.inverse_transform(ak_regressor.predict(X_test[4].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating code for classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_class = train.loc[:, ['carbon', 'manganese', 'phosphorus',\n",
    "              'sulfur', 'silicon', 'aluminium', 'niobium',\n",
    "              'vanadium', 'gauge', 'width',\n",
    "              'weight', 'linear feat', 'price']].values\n",
    "\n",
    "y_train_class = train.loc[:, \"defect_code\"].values\n",
    "\n",
    "\n",
    "\n",
    "X_test_class = test.loc[:, ['carbon', 'manganese', 'phosphorus',\n",
    "              'sulfur', 'silicon', 'aluminium', 'niobium',\n",
    "              'vanadium', 'gauge', 'width',\n",
    "              'weight', 'linear feat', 'price']].values\n",
    "\n",
    "\n",
    "\n",
    "y_test_class = test.loc[:, \"defect_code\"].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# standardizing input data for mlp classification \n",
    "\n",
    "x_scaler_class = StandardScaler()  \n",
    "x_scaler_class.fit(X_train_class)  \n",
    "\n",
    "X_train_class = x_scaler_class.transform(X_train_class)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "X_test_class = x_scaler_class.transform(X_test_class)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# labeling output data for mlp regression \n",
    "\n",
    "y_train_class = y_train_class.reshape(-1,1)\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "encoder.fit(y_train_class)\n",
    "\n",
    "y_train_class = encoder.transform(y_train_class)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# apply same transformation to test data\n",
    "\n",
    "y_test_class = y_test_class.reshape(-1,1)\n",
    "\n",
    "y_test_class = encoder.transform(y_test_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling y data\n",
    "\n",
    "# Create the encoder.\n",
    "\n",
    "    # Assume for simplicity all features are categorical.\n",
    "\n",
    "# Apply the encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak_classifer = MLPClassifier()\n",
    "\n",
    "ak_classifer.fit(X_train_class, y_train_class)\n",
    "\n",
    "ak_classifer.score(X_test_class, y_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
